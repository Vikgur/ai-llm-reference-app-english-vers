Назначение:
– показать понимание внутреннего устройства LLM

Тезисы:
– выбранный тип модели (decoder-only, minimal transformer)
– токенизация (что, почему, ограничения)
– embeddings (token + positional)
– self-attention и FFN на концептуальном уровне
– decoding стратегии
– ограничения модели (не production LLM, а reference)

Связи:
– используется architecture.md как контекст
– используется llm-security.md для указания attack surfaces
– связан с app/llm/* кодом (как навигация)